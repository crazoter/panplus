<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: jsmpeg/ts-tracker.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: jsmpeg/ts-tracker.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * @file The TSTracker class injects code into the page to detect when a TS file is loaded. Currently also handles processing of TS files to detect silences.
 */
TSTracker = (() => {
    /**
     * The TSTracker class injects code into the page to detect when a TS file is loaded. Currently also handles processing of TS files to detect silences.
     */
    class TSTracker {
        /**
         * Initialize with regards to settings
         * @param {Object} settings Settings object
         */
        constructor(settings) {
            if (settings[Settings.keys.silencetrimming]) {
                this.init();
            }
        }

        /**
         * Initialization, setup a bridge to detect which TS files are loaded
         * @returns {undefined}
         */
        init() {
            //return;//temporarily disable feature
            var self = this;
            this.timeArr = [];
            this.distanceArr = [];
            this.maxBufferedTSFilesLimit = 20;
            this.minBufferedTSFilesLimit = 14;
            this.bufferArrayBufferTimeout = 500;
            this.bufferArrayBufferSecondTimeout = 30000;
            this.bufferedTSFiles = [];
            this.bufferedTSFilesMetadata = [];
            this.bufferLastPushTime = Date.now();
            this.processedTSFilesMap = {}; //Prevent duplicate processing
            //this.OSTree = new OrderStatisticTree();
            //this.samplesBeforeCalculatingThreshold = 
            this.noiseReferenceLineFeatures = null;
            this.noiseReferenceCallbacks = $.Callbacks();

            this.VADWorker = new Worker(chrome.runtime.getURL('/panopto/js/jsmpeg/vad-worker.js'));
            this.VADWorker.onmessage = (event) => {
                if (event.data) {
                    switch (event.data.msgEnum) {
                        case MessageEnums.NORMAL_RESULTS:
                            //debugger;
                            //console.log("TSTracker NORMAL RES:", event.data);
                            //After merging, the start times are at their approprate locations
                            this.insertSilentSections(event.data.options.id, event.data.data.results);
                            break;
                        case MessageEnums.RAW_DATA_RESULTS: 
                            //console.log(event.data.data);
                            this.logDataForR(startTime, event.data.data);
                            break;
                        case MessageEnums.NOISE_RESULTS: 
                            console.log("TSTracker NOISE RES: ", event.data.data);
                            if (!event.data.data || !event.data.data.results) throw new Error("Invalid noise reference line features");
                            this.noiseReferenceLineFeatures = event.data.data.results;
                            this.noiseReferenceCallbacks.fire();
                            this.noiseReferenceCallbacks.empty();
                            break;
                        case MessageEnums.DEBUG: 
                            console.log("TSTracker DEBUG: ");
                            console.log(event.data.data);
                            //debugger;
                            break;
                        case MessageEnums.DEBUG_HISTOGRAM:
                            break;
                        case MessageEnums.ERROR:
                            debugger;
                            break;
                    }
                } else {
                    console.warn("TSTracker processor returns undefined results");
                }
            };

            VideosLoadedEvent.subscribe(() => {
                //This function is called in the user environment
                //#region injected function
                var injectedFunc = () => {
                    //Optimize the loading of TS files and buffering
                    let players = [];
                    players.push(flowplayer(0));
                    //If has second player
                    if (Panopto.Viewer.Viewer.activeSecondary()) {
                        players.push(flowplayer(1));
                    }
                    
                    //Set configs for optimization
                    //Disabled because causing some problems for some webcasts
                    /*
                    players.forEach(player => {
                        player.engine.hlsjs.config.startFragPrefetch = true;
                        player.engine.hlsjs.currentLevel = 0;
                        player.engine.hlsjs.config.maxFragLookUpTolerance = 0.20;
                        player.engine.hlsjs.config.maxStarvationDelay = 0.5;
                        player.engine.hlsjs.config.maxBufferLength = 360;
                        player.engine.hlsjs.config.maxMaxBufferLength = 600;
                        player.engine.hlsjs.config.maxBufferSize = 60000000;
                        player.engine.hlsjs.config.stretchShortVideoTrack = true;
                    });*/

                    let promiseChain = null;
                    let waitForPromiseChainResolve = null;
                    let waitForPromiseChain = new Promise(resolve => { waitForPromiseChainResolve = resolve; });

                    var request = function(url, frag, options) {
                        if (!promiseChain) {
                            //Initialize the promise chain with the noise request as the first promise
                            if (options &amp;&amp; options.isNoiseSample) {
                                promiseChain = requestFx(url, frag, options);
                                waitForPromiseChainResolve();
                            } else {
                                //If there were others that came before, get them to wait, then add them to the chain later
                                waitForPromiseChain.then(() => {
                                    promiseChain.then(requestFx(url, frag, options));
                                });
                            }
                        } else {
                            //Initialized, chain more promises
                            promiseChain.then(requestFx(url, frag, options));
                        }
                    }
                    
                    var requestFx = function(url, frag, options) {
                        return new Promise((resolve) => {
                            if (!options)
                                options = {isNoiseSample: false, startProcessingFrom: 0};
                            //https://stackoverflow.com/questions/33902299/using-jquery-ajax-to-download-a-binary-file
                            //Make the request in the webpage environment in case there are any CORS issues
                            var req = new XMLHttpRequest();
                            req.open("GET", url, true);
                            req.responseType = "arraybuffer";
                            //console.log("TS Request", url);
                            req.onload = function(e) {
                                bridgeSendData({frag: {
                                        relurl: frag.relurl,
                                        start: frag.start,
                                        duration: frag.duration,
                                        url: frag.url
                                    }, data: req.response, options: options});
                                resolve();
                            };
                            req.send();
                        });
                    }

                    var noiseTSParameters = async function(url) {
                        let tmp = url.substr(0,url.lastIndexOf('/') + 1);
                        let indexFilePath = `${tmp}index.m3u8`;
                        let indexFileData = null;
                        try {
                            indexFileData = await $.ajax({url: indexFilePath});
                        } catch (err) { console.error(err); }
                        if (indexFileData) {
                            indexFileData = indexFileData.split('\n');
                            //Use the last 1.3s of the last TS file, assume the last 1s is just noise. 
                            //The noise reference will only use 100ms
                            //Notice that panopto sometimes "Fades out" the last second of the webcast
                            let startProcessingFrom = 1.3;
                            let lastTSUrl = "";
                            let lastTSId = "";
                            let foundDataNeeded = 0;
                            for (let i = indexFileData.length - 1; i > 0; i--) {
                                if (indexFileData[i].indexOf(".ts") > -1) {
                                    lastTSId = indexFileData[i];
                                    lastTSUrl = `${tmp}${lastTSId}`;
                                    foundDataNeeded++;
                                }
                                else if (indexFileData[i].indexOf("#EXTINF:") > -1) {
                                    //Let value be the duration - 1.3s
                                    startProcessingFrom = parseFloat(indexFileData[i].substring(8, indexFileData[i].length - 1)) - startProcessingFrom;
                                    foundDataNeeded++;
                                    if (startProcessingFrom &lt; 0) {
                                        //If last TS was too short, use the 2nd last TS instead
                                        startProcessingFrom *= -1;//Reset startProcessingFrom
                                        // 512 / 48000 * 30 samples
                                        if (startProcessingFrom &lt; 0.330) startProcessingFrom = 0.330;//ensure there's enough time 
                                        foundDataNeeded = 0;
                                    }
                                }
                                if (foundDataNeeded >= 2) 
                                    break;
                            }
                            return {url: lastTSUrl, options: {isNoiseSample: true, startProcessingFrom: startProcessingFrom, id: lastTSId}};
                        } else return null;
                        //return `${tmp}${new Array(url.length - tmp.length - 3).fill(0).join('')}.ts`;
                    }

                    let noiseSampleRequested = false;
                    //Make use of the flowplayer on the website to keep us updated on TS files are in use
                    //This automatically picks the 1st video which should carry the audio
                    let listenerFired = false;
                    let fragsListened = {};
                    let addListener = function() {
                        players[0].engine.hlsjs.observer.addListener("hlsFragLoading",(callbackId, details) => {
                            listenerFired = true;
                            if(fragsListened[details.frag.relurl] == null) {
                                fragsListened[details.frag.relurl] = 1;
                                if (!noiseSampleRequested) {
                                    noiseTSParameters(details.frag.url).then((params) => {
                                        if (params) {
                                            request(params.url, details.frag, params.options);
                                            noiseSampleRequested = true;
                                        }
                                    });
                                }
                                request(details.frag.url, details.frag);
                            }
                        });
                    };
                    addListener();
                    
                    let loop = function() {
                        window.setTimeout(function() {
                            console.log("ListenerTracker", fragsListened, listenerFired);
                            if (!listenerFired) {
                                addListener();
                                loop();
                            }
                        }, 500);
                    }
                    loop();

                    console.log("TS-Tracker initialized");
                };
                //#endregion

                //Context bridge to handle data from page
                var ctxBridge = new ContextBridge(injectedFunc, "TsTrackingEvent", (event) => {
                    if (event != undefined &amp;&amp; event.detail != undefined &amp;&amp; event.detail.data != undefined) {
                        if (!self.processedTSFilesMap[event.detail.frag.relurl] || event.detail.options.isNoiseSample) {
                            if (!event.detail.options.isNoiseSample) {
                                self.processedTSFilesMap[event.detail.frag.relurl] = 1;
                            }
                            /*
                            let options = {
                                isNoiseSample: event.detail.options.isNoiseSample,
                                startProcessingFrom: event.detail.options.startProcessingFrom,
                                id: event.detail.options.id || event.detail.frag.relurl,
                                startTime: event.detail.frag.start,
                                duration: event.detail.frag.duration,
                            };*/

                            //return;
                            //console.log('TsTrackingEvent', event.detail.data, event.detail.options);
                            self.process(event.detail.data, {
                                isNoiseSample: event.detail.options.isNoiseSample,
                                startProcessingFrom: event.detail.options.startProcessingFrom,
                                id: event.detail.options.id || event.detail.frag.relurl,
                                startTime: event.detail.frag.start,
                                duration: event.detail.frag.duration,
                            });
                        }
                    } else {
                        debugger;
                    }
                });
                ctxBridge.connect();
            });
        };

        /**
         * Process the arraybuffer and pass it into an audio context to be decoded
         * Also, audiocontext cannot be created in worker.
         * https://github.com/WebAudio/web-audio-api/issues/1098
         * We'll continue to demux &amp; decode in the UI thread before passing it to our worker to process the silent sections.
         * Passing it back and forth (for demux) accrues some overhead even with zero-copy. No time to benchmark, so we'll keep it as it is for now.
         * 
         * @param {ArrayBuffer} arraybuffer array buffer, data
         * @param {Object} options {isNoiseSample: boolean, startProcessingFrom: relative time, id: "00123.ts", startTime: Number, duration: Number};
         * @returns {undefined}
         */
        process(arraybuffer, options) {
            //This will be a AAC LC file
            //This processing can maybe be done in a web worklet
            var audioByteStream = WebModule["MPEG2TS"].toByteStream(WebModule["MPEG2TS"].demux(new Uint8Array(arraybuffer), 0).AUDIO_TS_PACKET);
            //Some browsers may not support AAC but chrome does
            if (options.isNoiseSample) {
                this.decodeAudioData(audioByteStream, options);
            } else {
                this.waitForNoiseSample().then(() => {
                    this.decodeAudioData(audioByteStream, options);
                    //this.bufferArrayBuffer(audioByteStream, options);
                });
            }
        }

        /**
         * Decode the audio data and pass it into an audio context to be decoded
         * @param {Uint8Array} audioByteStream data
         * @param {Object} options {isNoiseSample: boolean, startProcessingFrom: relative time, id: "00123.ts", startTime: Number, duration: Number};
         * @returns {undefined}
         */
        decodeAudioData(audioByteStream, options) {
            //console.log(audioByteStream);
            //https://stackoverflow.com/questions/8074152/is-there-a-way-to-use-the-web-audio-api-to-sample-audio-faster-than-real-time
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            audioCtx.decodeAudioData(Uint8ArrayToArrayBuffer(audioByteStream), 
                (audioBuffer) => {
                    options.sampleRate = audioBuffer.sampleRate;
                    options.duration = audioBuffer.duration;
                    options.float32Length = audioBuffer.length;
                    options.silenceThreshold = Settings.getDataAsObject()[Settings.keys.silencethreshold];
                    //console.log(options.silenceThreshold);
                    //Convert to ArrayBuffers for transfer
                    const channel0 = audioBuffer.getChannelData(0).buffer;
                    const channel1 = audioBuffer.getChannelData(1).buffer;
                    //Send to VADWorker for processing
                    this.VADWorker.postMessage({data: [channel0, channel1], options: options}, [channel0, channel1]);
                    audioCtx.close();
                },
                (err) => { console.error("Error with decoding audio data" + err.err); });
        }

        /**
         * Wait for noise sample, only proceed after noise has been processed
         * @returns {Promise} Promise with resolve with 0 parameters. Just waits for the noise reference to be created.
         */
        waitForNoiseSample() {
            return new Promise((resolve) => {
                if (this.noiseReferenceLineFeatures == null)
                    this.noiseReferenceCallbacks.add(() => { resolve(); });
                else resolve();
            });
        }
        
        /**
         * Used to generate csv data for processing later in R.
         * @param {Number} startTime Starting time of the TS file
         * @param {Array} data {results: Array of distances, interval: Interval between each calculated distance}
         */
        logDataForR(startTime, data) {
            for (let i = 0; i &lt; data.results.length; i++) {
                this.timeArr.push(+(startTime * data.interval * i).toFixed(1));
            }
            this.distanceArr = this.distanceArr.concat(data.results);
            if (this.timeArr.length > 30000) {
                var dataCSV = "time,dist\n";
                for (let i = 0; i &lt; this.timeArr.length; i++) {
                    dataCSV += `${this.timeArr[i]},${this.distanceArr[i]}\n`;
                }
                /* R commands
                myData &lt;- read.csv(file="D:/Study/Y1 Summer/Panopto Project/Others/Webcast R analysis/2.csv", header=TRUE, sep=",")
                hist(myData$dist, breaks=1000)
                par(pch=22, col="red");heading = paste("type=","h");plot(myData$time, myData$dist, type="n", main=heading);lines(myData$time, myData$dist, type="h") 
                */
                return dataCSV;//Only return something so they don't garbage collect my dataCSV
            }
        }

        /**
         * Take the results from the webworklet and insert into the video as cues
         * @param {String} id relurl of the ts file being retrieved
         * @param {Number} startTime start time of the TS file
         * @param {Object} results array, [isSpeaking: true=was not speaking then started,false=was speaking then stopped, time: currentTime relative to start of TS file]
         * @returns {undefined}
         */
        insertSilentSections(id, data) {
            //data.forEach(x => x.time += startTime);
            //Todo: cache
            SilenceCueManager.addToCache(id, data);
            SilenceCueManager.addSilenceCues(id, data);
        }
    }

    return TSTracker;
})();</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Cache.html">Cache</a></li><li><a href="CarouselManager.html">CarouselManager</a></li><li><a href="ContextBridge.html">ContextBridge</a></li><li><a href="DelayDisabler.html">DelayDisabler</a></li><li><a href="LoggerDisabler.html">LoggerDisabler</a></li><li><a href="MinHeap.html">MinHeap</a></li><li><a href="Settings.html">Settings</a></li><li><a href="Sidebar.html">Sidebar</a></li><li><a href="SilenceCueManager.html">SilenceCueManager</a></li><li><a href="SpeedSlider.html">SpeedSlider</a></li><li><a href="Template.html">Template</a></li><li><a href="Transcript.html">Transcript</a></li><li><a href="TranscriptDisplay.html">TranscriptDisplay</a></li><li><a href="TranscriptRequester.html">TranscriptRequester</a></li><li><a href="TranscriptSource.html">TranscriptSource</a></li><li><a href="TranscriptSourcePanopto.html">TranscriptSourcePanopto</a></li><li><a href="TSTracker.html">TSTracker</a></li><li><a href="VADProcessor.html">VADProcessor</a></li><li><a href="VolumeBooster.html">VolumeBooster</a></li></ul><h3>Global</h3><ul><li><a href="global.html#concatUint8Arrays">concatUint8Arrays</a></li><li><a href="global.html#getModuleId">getModuleId</a></li><li><a href="global.html#getWebcastId">getWebcastId</a></li><li><a href="global.html#MessageEnums">MessageEnums</a></li><li><a href="global.html#resolvePrecept">resolvePrecept</a></li><li><a href="global.html#SettingsPage">SettingsPage</a></li><li><a href="global.html#sleep">sleep</a></li><li><a href="global.html#Uint8ArrayToArrayBuffer">Uint8ArrayToArrayBuffer</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 3.6.2</a> on Fri Jul 19 2019 19:03:23 GMT+0800 (Singapore Standard Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
